// Auto-generated from Supabase database
import type { Paper } from '../types/paper'

export const mockPapers: Paper[] = [
  {
    "id": "3b47355b-881c-4e6b-ae36-351720de8e6b",
    "title": "The Dual Benefits of Advanced Automation Systems",
    "slug": "the-dual-benefits-of-advanced-automation-systems",
    "category": "automation",
    "description": "In today’s fast-paced digital landscape, businesses and software engineers alike seek solutions that can streamline operations, ensure data security, and provide superior user experiences. This paper delves into the comprehensive benefits of advanced automation systems, exploring how they enhance operational efficiency, improve data management, and offer robust authentication for business owners. Additionally, it provides a detailed guide for software engineers on leveraging modern full stack technologies to create powerful, scalable, and secure applications. Learn how integrating innovative systems can drive business success and foster technological innovation.",
    "content": "“Unlocking Efficiency and Innovation: The Dual Benefits of Advanced Automation Systems” provides an in-depth analysis of the significant advantages offered by modern automation systems for both business owners and software engineers. For business decision-makers, the paper highlights how these systems enhance user experience, operational efficiency, data management, and security. For software engineers, it offers a detailed roadmap on using full stack technologies like Next.js, React, Notion API, and Vercel Postgres to build robust and scalable applications. This comprehensive guide underscores the transformative impact of advanced automation systems on business operations and software development.",
    "html_content": "<h1 ><strong >The Business Benefits of the System</strong></h1><h2 ><strong >Section 1: Benefits for Business Owners</strong></h2><h3 ><strong >Enhanced User Experience</strong><br></h3><p >The system uses advanced technologies to provide a smooth and engaging experience for users. With features like a personalized dashboard, real-time updates, and interactive content, the system ensures users have a positive experience, which leads to higher satisfaction and more returning users. This increased user retention and loyalty can significantly boost revenue by encouraging repeat business and enhancing customer lifetime value.<br></p><p ><strong >Key Points:</strong></p><ul ><li >‍<strong >Personalized Dashboard:</strong> Users can see their progress and get tailored recommendations.<strong >‍</strong></li><li ><strong >Real-Time Updates:</strong> Keeps information current and users engaged.<strong >‍</strong></li><li ><strong >Interactive Content:</strong> Keeps users interested and coming back.<strong >‍</strong></li><li ><strong >Increased User Retention:</strong> Higher satisfaction leads to more repeat business and greater customer lifetime value.<br></li></ul><h3 ><strong >Increased Operational Efficiency</strong><br></h3><p >Automation is key to improving efficiency. The system automates data entry, calculations, and updates, reducing the need for manual work. This saves time and reduces errors, ensuring data is accurate and reliable. The cost savings from reduced manual labor can be redirected into growth initiatives, while faster service delivery can enhance customer satisfaction and justify premium pricing, further boosting revenue.<br></p><p ><strong >Key Points:</strong></p><ul ><li >‍<strong >Automated Data Processing:</strong> Cuts down on manual effort and mistakes.<strong >‍</strong></li><li ><strong >Efficient Data Retrieval:</strong> Quick access to user data for timely updates.<strong >‍</strong></li><li ><strong >Scalability:</strong> Can handle more users without slowing down.<strong >‍</strong></li><li ><strong >Cost Savings:</strong> Reduced labor costs can improve profit margins.<strong >‍</strong></li><li ><strong >Faster Service Delivery:</strong> Improved efficiency allows for higher pricing due to better service quality.<br></li></ul><h3 ><strong >Improved Data Management</strong><br></h3><p >Good data management is crucial for making smart business decisions. The system’s structured approach ensures all user data is well-organized and easy to access, helping quickly retrieve and process information to give accurate recommendations. Effective data management also supports personalized marketing efforts, which can increase conversion rates and drive sales.<br></p><p ><strong >Key Points:</strong></p><ul ><li >‍<strong >Organized Data Storage:</strong> Keeps user data categorized and stored efficiently.<strong >‍</strong></li><li ><strong >Quick Data Retrieval:</strong> Ensures timely and accurate recommendations.<strong >‍</strong></li><li ><strong >Informed Decision-Making:</strong> Better data management leads to better business decisions.<strong >‍</strong></li><li ><strong >Personalized Marketing:</strong> Targeted campaigns based on user data can increase sales.<br></li></ul><h3 ><strong >Secure and Reliable Authentication</strong><br></h3><p >Security is essential in any user-focused platform. The system uses strong authentication methods to protect user data and ensure that only authorized users can access sensitive information. This builds trust with users and meets data protection regulations. Strong security measures also prevent costly breaches, protecting revenue and enhancing the business’s reputation.<br></p><p ><strong >Key Points:</strong></p><ul ><li >‍<strong >Strong Authentication:</strong> Ensures data security.<strong >‍</strong></li><li ><strong >User Trust:</strong> Secure systems build confidence among users.<strong >‍</strong></li><li ><strong >Regulatory Compliance:</strong> Meets data protection standards.</li><li ><strong >Preventing Breaches:</strong> Protects against financial losses from security incidents.</li><li ><strong >Attracting Customers:</strong> Builds trust with security-conscious users, expanding the customer base.</li></ul><h2 ><strong >Section 2: Benefits for Software Engineers</strong></h2><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:2598px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"2598px\"><div ><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/6669c15c844716a4ad55604a_diagram-export-6-12-2024-10_39_56-AM.svg\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" ></div></figure><h3 ><strong >Full Stack Code Stack</strong></h3><p >The system uses a modern full stack code stack, including Next.js, React, Notion API, and Vercel Postgres. This combination of technologies offers a powerful and flexible framework for building strong applications.</p><p ><strong >Key Points:</strong></p><ul ><li ><strong >Next.js and React:</strong> Provides a dynamic and responsive frontend.</li><li ><strong >Notion API:</strong> Efficiently manages and retrieves user data.</li><li ><strong >Vercel Postgres:</strong> Securely handles user authentication.</li></ul><h3 ><strong >Creating Similar Solutions</strong></h3><p >Software engineers can use these technologies to create similar systems by following these detailed steps:<strong >‍</strong></p><h4 ><strong >1. Dashboard Architecture</strong></h4><p >Build a dynamic dashboard using Next.js and React components. Use server-side rendering (SSR) and API routes to fetch and display user data. Make sure the dashboard is interactive and user-friendly.</p><p ><strong >Steps:</strong></p><ul ><li ><strong >Set Up Next.js and React:</strong> Create a project and install necessary dependencies.</li><li ><strong >Create React Components:</strong> Build reusable components like Layout, CustomCard, and RoadmapSnapshot.</li><li ><strong >Implement SSR and API Routes:</strong> Fetch data server-side for better performance.</li></ul><h4 ><strong >2. Quiz Logic</strong></h4><p >Implement quiz logic in a utility file (e.g., quizUtils.js). Include functions to calculate category percentages, completed steps, next steps, and the roadmap snapshot based on user responses.</p><p ><strong >Steps:</strong></p><ul ><li ><strong >Design Grading Scale:</strong> Assign percentage values to quiz answers.</li><li ><strong >Categorize Questions:</strong> Group questions into relevant categories.</li><li ><strong >Implement Calculation Functions:</strong> Write functions to process and calculate results based on user answers.<strong >‍</strong></li></ul><h4 >3. <strong >Database Integration</strong></h4><p >Integrate with databases like Notion for storing quiz responses and Vercel Postgres for managing user authentication. Ensure data is stored securely and can be retrieved quickly.</p><p ><strong >Steps:</strong></p><ul ><li ><strong >Set Up Notion API:</strong> Configure Notion to store and retrieve user data.</li><li ><strong >Implement Vercel Postgres:</strong> Manage user authentication and session data.</li><li ><strong >Create API Endpoints:</strong> Build endpoints for data submission, retrieval, and updates.</li></ul><h4 ><strong >4. API Routes</strong></h4><p >Develop API routes in Next.js to handle server-side logic and data retrieval. Secure these routes with proper authentication to protect user data.</p><p ><strong >Steps:</strong></p><ul ><li ><strong >Create API Routes:</strong> Implement routes for login, registration, quiz submission, and data retrieval.</li><li ><strong >Implement Authentication:</strong> Use JSON Web Tokens (JWT) and Vercel’s KV storage for session management.</li><li ><strong >Ensure Security:</strong> Protect routes with middleware to verify user sessions.</li></ul><p >By following these steps and using the technologies in the system, software engineers can build powerful, efficient, and secure applications that provide significant business benefits. The combination of modern frameworks and strong architecture ensures scalability, security, and an excellent user experience.</p>",
    "featured": 0,
    "published": 1,
    "reading_time": 4,
    "difficulty_level": "intermediate",
    "technical_focus": "",
    "thumbnail_image": "https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/6669e971ac00b0a0cf29e7a1_calculateCompletedSteps.png",
    "featured_image": "https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/6669e971ac00b0a0cf29e7a1_calculateCompletedSteps.png",
    "created_at": "2024-06-12T15:47:13.000Z",
    "updated_at": "2024-06-12T18:32:13.000Z",
    "is_hidden": 0,
    "archived": 0,
    "excerpt": null,
    "excerpt_short": null,
    "excerpt_long": null,
    "summary": null,
    "meta_title": null,
    "meta_description": null,
    "focus_keywords": null,
    "featured_card_image": null,
    "video_walkthrough_url": null,
    "interactive_demo_url": null,
    "resource_downloads": null,
    "prerequisites": null,
    "implementation_time": null,
    "view_count": 0,
    "published_at": null,
    "show_newsletter_cta": false,
    "webflow_item_id": null,
    "webflow_collection_id": null,
    "ascii_art": "\n███████████████████████████████████████\n███░░▒▓▓▓ AUTOMATE ▓▓▓▓▓▓▓▓▓▓▓▒░░███"
  },
  {
    "id": "413f17d7-6cf4-4520-9a13-3d1becb9c39b",
    "title": "Web Scraper and Airtable Integration with Next.js",
    "slug": "web-scraper-and-airtable-integration-with-next-js",
    "category": "automation",
    "description": "No description available",
    "content": "Content not available",
    "html_content": "<h3 >The Problem</h3><p >Imagine you want to keep track of the templates available on the Webflow website. You’re interested in monitoring when new templates are added and when existing templates are removed from the homepage. Manually checking the website and updating a spreadsheet would be a tedious and time-consuming task. That’s where our Next.js web scraper and Airtable integration come into play.</p><h3 >The Solution</h3><p >We’ll build a Next.js application that scrapes the Webflow templates page, extracts relevant information, and stores it in an Airtable base. The application will consist of two main components:</p><ol ><li ><strong >Webflow Scraper API Route</strong>:</li></ol><ul ><li >The <code >webflow-scraper.js</code> file defines an API route that fetches the HTML content of the Webflow templates page using the <code >axios</code> library.</li><li >It then uses the <code >cheerio</code> library to parse the HTML and extract the desired data, such as the template name, URL, and publish date.</li><li >The scraped data is returned as a JSON response.</li></ul><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:680px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"680px\"><div ><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665d24dfab1ad0ab4b9cd843_page-scraper.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" ></div></figure><p ><strong >2. Compare and Update API Route</strong>:</p><ul ><li >The <code >compare-and-update.js</code> file defines another API route that compares the scraped data with the existing records in the Airtable base.</li><li >It fetches the scraped data from the Webflow Scraper API route and retrieves all records from the specified Airtable table.</li><li >It compares the scraped data with the Airtable records to identify new templates and templates that have been removed from the homepage.</li><li >For new templates, it creates new records in the Airtable table.</li><li >For templates that exist in Airtable but are no longer on the homepage, it updates the “Last Time on Home Page” field with the current date.<code >‍</code></li></ul><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:680px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"680px\"><div ><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665d2588cd6d99dbaa741c18_fetch-parser.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\" width=\"auto\" height=\"auto\" ></div></figure><h3 >Airtable Integration</h3><p >To integrate with Airtable, we use the <code >airtable</code> package and configure it with our Airtable API key and base ID. We define the necessary field IDs and table name in the <code >lib/airtable.js</code> file, making it easy to reference them throughout the application.</p><h3 >Scheduled Execution</h3><p >To automate the scraping and comparison process, we utilize the Vercel Cron Jobs feature. By adding a <code >vercel.json</code> file with the desired cron schedule, we can configure the <code >compare-and-update</code> API route to run at specific intervals (e.g., every 12 hours). This ensures that our Airtable base stays up to date with the latest changes on the Webflow templates page.<code >‍</code></p><figure class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665d25deadc8424d31f03485_json.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"></div></figure><p ></p>",
    "featured": 0,
    "published": 1,
    "reading_time": 2,
    "difficulty_level": "intermediate",
    "technical_focus": "",
    "thumbnail_image": "https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665d24dfab1ad0ab4b9cd843_page-scraper.png",
    "featured_image": "https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665d24dfab1ad0ab4b9cd843_page-scraper.png",
    "created_at": "2024-06-03T02:10:30.000Z",
    "updated_at": "2024-06-03T17:03:18.000Z",
    "is_hidden": 0,
    "archived": 0,
    "excerpt": null,
    "excerpt_short": null,
    "excerpt_long": null,
    "summary": null,
    "meta_title": null,
    "meta_description": null,
    "focus_keywords": null,
    "featured_card_image": null,
    "video_walkthrough_url": null,
    "interactive_demo_url": null,
    "resource_downloads": null,
    "prerequisites": null,
    "implementation_time": null,
    "view_count": 0,
    "published_at": null,
    "show_newsletter_cta": false,
    "webflow_item_id": null,
    "webflow_collection_id": null,
    "ascii_art": "\n███████████████████████████████████████\n███░░▒▓▓▓ AUTOMATE ▓▓▓▓▓▓▓▓▓▓▓▒░░███"
  },
  {
    "id": "e3e48af7-9fa1-406a-8ec7-70090176a04e",
    "title": "Gmail to Notion Sync",
    "slug": "gmail-to-notion-sync",
    "category": "automation",
    "description": "The Next.js app we'll be exploring is designed to sync emails from a Gmail account to Notion databases. It provides a seamless way to capture email data and store it in a structured format within Notion. The app leverages the power of Next.js, a popular React framework, to build a fast and efficient web application.",
    "content": "The Next.js app we'll be exploring is designed to sync emails from a Gmail account to Notion databases. It provides a seamless way to capture email data and store it in a structured format within Notion. The app leverages the power of Next.js, a popular React framework, to build a fast and efficient web application.",
    "html_content": "<h2 ><strong >1. Introduction</strong></h2><p >The Next.js app we'll be exploring is designed to sync emails from a Gmail account to Notion databases. It provides a seamless way to capture email data and store it in a structured format within Notion. The app leverages the power of Next.js, a popular React framework, to build a fast and efficient web application.</p><h2 ><strong >2. Prerequisites</strong></h2><p >Before diving into the app's features and functions, ensure that you have the following prerequisites:</p><ul ><li >Node.js installed on your machine</li><li >Basic knowledge of Next.js and React</li><li >Familiarity with JavaScript and TypeScript</li><li >A Gmail account with the \"log\" label configured</li><li >A Notion account with the necessary permissions</li></ul><h2 ><strong >3. Setting Up the Next.js App</strong></h2><p >To get started, create a new Next.js app using the following command:</p><p ><code >npx create-next-app@latest next-notion-email-sync</code></p><p >Choose the appropriate options for your project, such as the programming language (JavaScript or TypeScript) and the styling framework (e.g., Tailwind CSS).</p><p >Navigate to the project directory:</p><p ><code >cd next-notion-email-sync</code></p><p >Install the required dependencies:</p><p ><code >npm install @notionhq/client nookies</code></p><h2 ><strong >4. Configuring Environment Variables</strong></h2><p >Create a <code >.env.local</code> file in the root directory of your project and add the following environment variables:</p><figure class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665df2aeba05d5c48fdfb3bd_envlocal.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"></div></figure><p >Replace the placeholders with your actual values obtained from the Google and Notion developer consoles.</p><h2 ><strong >5. Implementing Gmail Authentication</strong></h2><p >Create a new file <code >pages/api/auth/login.js</code> and add the following code:</p><figure class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665df24f1f919f2ee06057e9_google-login.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"></div></figure><p >This API route handles the Gmail authentication process by redirecting the user to the Google authentication URL.</p><p >Create a new file <code >lib/googleAPI.js</code> and implement the <code >getGoogleAuthURL</code> function:</p><figure class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665df201da1cd599d35e3a64_google.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"></div></figure><p >This function generates the Google authentication URL with the necessary scopes and configuration.</p><p >Create a new file <code >pages/api/auth/callback.js</code> to handle the callback from the Google authentication flow:</p><figure class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665df4ac46c8f26289075c34_google-callback.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"></div></figure><p >This API route handles the callback from the Google authentication flow, retrieves the access token, and stores it in the session.</p><p >Implement the <code >getTokens</code> function in <code >lib/googleAPI.js</code>:</p><figure class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665df495af6361d0e5945687_google-tokens.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"></div></figure><p >This function exchanges the authorization code for access tokens.</p><h2 ><strong >6. Syncing Emails from Gmail</strong></h2><p >Create a new file <code >pages/api/sync.js</code> to handle the email syncing process:</p><figure class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665df4806a885bf2a5bd54e4_google-sync.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"></div></figure><p >This API route handles the email syncing process. It retrieves the access token and user email from the session, fetches the emails using the <code >fetchEmails</code> function from <code >lib/googleAPI.js</code>, and returns a success or error response.</p><p >Implement the <code >fetchEmails</code> function in <code >lib/googleAPI.js</code>:</p><figure class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665df42a8e9a68513d94535b_google-fetch.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"></div></figure><p >This function fetches emails from the user's Gmail account using the Gmail API. It retrieves the messages with the \"log\" label, extracts the relevant email data, and updates the synced email count using the <code >/api/update-synced-email-count</code> API route.</p><h2 ><strong >7. Implementing Notion Authentication</strong></h2><p >Create a new file <code >lib/notionAPI.js</code> and add the following code:</p><figure class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665df421a1a6b35122d45774_notionAPI.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"></div></figure><p >This file contains functions for handling Notion authentication. The <code >getNotionAuthURL</code> function returns the Notion authorization URL, and the <code >exchangeCodeForToken</code> function exchanges the authorization code for an access token and retrieves the user's databases.</p><p >Create a new file <code >pages/api/auth/notion/callback.js</code> to handle the callback from the Notion authentication flow:</p><figure class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665df419bfdd71ede1ec5fed_notion-callback.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"></div></figure><p >This API route handles the callback from the Notion authentication flow. It exchanges the authorization code for an access token, retrieves the user's databases, and stores them in cookies.</p><h2 ><strong >8. Selecting Notion Databases</strong></h2><p >Create a new file <code >components/database-setup.tsx</code> to handle the database selection process:</p><figure class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665df40ecba10ae3acfdc39a_database-setup.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"></div></figure><p >This component handles the database selection process. It allows the user to select the Contacts and Interactions databases from the available options and maps the email fields to the corresponding database fields.</p><p >Create a new file <code >pages/database-setup.js</code> to render the <code >DatabaseSetup</code> component:</p><figure class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665df405ba92e6ee3bf91732_database-setup-page.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"></div></figure><p >This page component renders the <code >DatabaseSetup</code> component and passes the necessary props. It retrieves the databases from the <code >notionDatabases</code> cookie and handles the form submission by storing the selected database IDs and field mappings in cookies.</p><h2 ><strong >9. Mapping Email Fields to Notion Database Properties</strong></h2><p >In the <code >DatabaseSetup</code> component, the <code >contactsFieldMappings</code> and <code >interactionsFieldMappings</code> state variables handle the mapping of email fields to the corresponding database fields.</p><p >The <code >contactsFieldMappings</code> array contains objects with the following structure:</p><figure class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665df3fada712c9706f40da7_contactsFieldMappings.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"></div></figure><ul ><li ><code >emailField</code> represents the field from the email object (e.g., \"sender\", \"senderEmail\").</li><li ><code >databaseField</code> represents the corresponding field in the Contacts database.</li></ul><p >Similarly, the <code >interactionsFieldMappings</code> array contains objects with the same structure, mapping email fields to the corresponding fields in the Interactions database.</p><p >The dropdown menus in the <code >DatabaseSetup</code> component allow the user to select the appropriate database fields for each email field. The selected mappings are stored in the respective state variables.</p><h2 ><strong >10. Syncing Emails to Notion Databases</strong></h2><p >Create a new file <code >lib/notionAPI.js</code> and add the following functions:</p><figure class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665df3f15dd569da7a8a6826_notionAPI-lib.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"></div></figure><p >The <code >addEmailToDatabase</code> function adds an email to a Notion database. It takes the email properties, access token, and database ID as parameters and creates a new page in the specified database using the Notion API.</p><p >The <code >getSyncedEmailIds</code> function retrieves the synced email IDs from a Notion database. It uses the access token and the sync database ID stored in <code >localStorage</code> to query the database and extract the email IDs.</p><p >Update the <code >handleSync</code> function in the <code >DatabaseSetup</code> component to sync the emails to the selected Notion databases:</p><figure class=\"w-richtext-figure-type-image w-richtext-align-center\" data-rt-type=\"image\" data-rt-align=\"center\"><div><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665df3e99e463a47a7bc78aa_handlesync.png\" loading=\"lazy\" alt=\"__wf_reserved_inherit\"></div></figure><p >This updated <code >handleSync</code> function retrieves the access token from cookies, iterates over the emails, maps the email fields to the corresponding database properties based on the field mappings, and calls the <code >addEmailToDatabase</code> function to sync each email to the selected Contacts and Interactions databases.</p><h2 ><strong >11. Handling Errors and Edge Cases</strong></h2><p >Throughout the app, error handling is implemented to catch and handle potential errors gracefully. Here are a few examples:</p><ul ><li >In the API routes, try-catch blocks are used to catch errors and return appropriate error responses.</li><li >In the <code >fetchEmails</code> function, errors are caught and logged, and an error is thrown to propagate the error to the calling code.</li><li >In the <code >addEmailToDatabase</code> and <code >getSyncedEmailIds</code> functions, errors are caught, logged, and thrown to handle them appropriately.</li></ul><p >It's important to handle edge cases and provide meaningful error messages to the user when something goes wrong. You can display error messages using UI components or alert the user with appropriate notifications.</p><h2 ><strong >12. Styling and UI Components</strong></h2><p >The app uses Tailwind CSS for styling and includes various Shadcn UI components to enhance the user experience. Here are a few notable components:</p><ul ><li ><code >Button</code>: A reusable button component with different variants and sizes.</li><li ><code >DropdownMenu</code>: A dropdown menu component used for selecting databases and mapping fields.</li><li ><code >Table</code>: A table component used for displaying the field mappings.</li></ul><p >These components are styled using Tailwind CSS classes to achieve a consistent and visually appealing design.</p><h2 ><strong >13. Deploying the App</strong></h2><p >To deploy the Next.js app, you can use platforms like Vercel or Netlify. These platforms provide seamless integration with Next.js and offer easy deployment workflows.</p><p >Make sure to set the necessary environment variables in your deployment platform's settings to match your production environment.</p><h2 ><strong >14. Conclusion</strong></h2><p >In this tutorial, we explored the features and functions of a Next.js app that syncs emails from a Gmail account to Notion databases. We covered the following key aspects:</p><ul ><li >Setting up the Next.js app and configuring environment variables</li><li >Implementing Gmail authentication and syncing emails</li><li >Implementing Notion authentication and selecting databases</li><li >Mapping email fields to Notion database properties</li><li >Syncing emails to Notion databases</li><li >Handling errors and edge cases</li><li >Styling and UI components</li><li >Deploying the app</li></ul><p >By following this guide, you should have a solid understanding of how the app works and be able to replicate or build upon it for your own purposes.</p><p >Remember to handle sensitive information securely, such as access tokens and client secrets, and ensure that your app follows best practices for security and performance.</p>",
    "featured": 0,
    "published": 1,
    "reading_time": 6,
    "difficulty_level": "intermediate",
    "technical_focus": "",
    "thumbnail_image": "https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665df4f9da1cd599d361585d_googleAPI.png",
    "featured_image": "https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665df4f9da1cd599d361585d_googleAPI.png",
    "created_at": "2024-06-02T18:13:40.000Z",
    "updated_at": "2024-06-03T17:03:06.000Z",
    "is_hidden": 0,
    "archived": 0,
    "excerpt": null,
    "excerpt_short": null,
    "excerpt_long": null,
    "summary": null,
    "meta_title": null,
    "meta_description": null,
    "focus_keywords": null,
    "featured_card_image": null,
    "video_walkthrough_url": null,
    "interactive_demo_url": null,
    "resource_downloads": null,
    "prerequisites": null,
    "implementation_time": null,
    "view_count": 0,
    "published_at": null,
    "show_newsletter_cta": false,
    "webflow_item_id": null,
    "webflow_collection_id": null,
    "ascii_art": "\n███████████████████████████████████████\n███░░▒▓▓▓ AUTOMATE ▓▓▓▓▓▓▓▓▓▓▓▒░░███"
  },
  {
    "id": "196d530a-67a6-47bc-b1d0-ed633f5dd545",
    "title": "Timesheets to QuickBooks",
    "slug": "timesheets-to-quickbooks",
    "category": "dashboard",
    "description": "Finance teams can reduce duplicate efforts in separate finance applications by developing an internal dashboard.",
    "content": "All of the information that is currently being tracked in separate finance applications - in one dashboard. By having this information in one place, finance teams will be able to see where duplicate efforts are being made and take steps to eliminate them.",
    "html_content": "<p >The development of an internal dashboard for finance teams can be a lengthy and complicated process, but it is a necessary one if teams are looking to reduce duplicate efforts in separate finance applications. </p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1294px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1294px\"><div ><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665cb0792e80417422079d82_63a9afd1d2940de36c906615_QBO%2520App%2520Screenshot.png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" ></div></figure><p >In order to create an effective and efficient dashboard, we first had to understand the data that they are working with and how it can be best presented. This process usually begins with a data analysis, which helps to identify trends and patterns within the data set. Once the data has been analyzed, we can then begin to develop visualizations for the dashboard. </p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1294px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1294px\"><div ><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665cb0792e80417422079d8a_63a9b2fda56bae419b8f08d6_QBO%2520App%2520Screenshot%2520(1).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" ></div></figure><p >These visualizations can take many different forms, but they should all be designed to help users quickly and easily understand the data. The final step in the process is to test the dashboard to ensure that it is functioning properly and that users are able to understand and use it effectively.</p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1294px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1294px\"><div ><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665cb0792e80417422079d96_63a9bd90a56bae21cb8feb9b_QBO%2520App%2520Screenshot%2520(3).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" ></div></figure><p >iDesign, which offers a collaborative and customized approach to developing online courses and degrees, had numerous applications in use by different teams across the organization. These teams were duplicating efforts in their respective applications, which created inefficiencies and data discrepancies.</p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1294px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1294px\"><div ><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665cb0792e80417422079d86_63a9bd9860216a1cd1a3d8d4_QBO%2520App%2520Screenshot%2520(4).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" ></div></figure><p >The iDesign team approached us to develop an internal dashboard that would allow finance teams to view data from the applications in one place. This would reduce duplicate efforts and improve data accuracy. We worked as a contractor on the Data Team to understand their requirements and developed a prototype of the dashboard. </p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1294px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1294px\"><div ><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665cb0792e80417422079d8f_63a9c6de90b0ca2960d1ce2d_QBO%2520App%2520Screenshot%2520(5).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" ></div></figure><p >We then worked with them to test the prototype and make sure it met their needs.</p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1294px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1294px\"><div ><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665cb0792e80417422079d92_63a9cd2efde34b7378e48d28_QBO%2520App%2520Screenshot%2520(6).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" ></div></figure><p >Once the dashboard was developed, we trained the client's finance teams on how to use it. We also provided support to the teams during the rollout of the dashboard.</p>",
    "featured": 0,
    "published": 1,
    "reading_time": 1,
    "difficulty_level": "intermediate",
    "technical_focus": "",
    "thumbnail_image": "https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665cb0792e80417422079d6f_63a9b099ecd82623fae54b2b_6396e687a93089cc625cf60a_QBO%2520Automation%2520angle%2520(4).png",
    "featured_image": "https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665cb19971af82242f264b23_timesheets.png",
    "created_at": "2024-06-02T17:48:42.000Z",
    "updated_at": "2024-06-02T17:53:31.000Z",
    "is_hidden": 0,
    "archived": 0,
    "excerpt": null,
    "excerpt_short": null,
    "excerpt_long": null,
    "summary": null,
    "meta_title": null,
    "meta_description": null,
    "focus_keywords": null,
    "featured_card_image": null,
    "video_walkthrough_url": null,
    "interactive_demo_url": null,
    "resource_downloads": null,
    "prerequisites": null,
    "implementation_time": null,
    "view_count": 0,
    "published_at": null,
    "show_newsletter_cta": false,
    "webflow_item_id": null,
    "webflow_collection_id": null,
    "ascii_art": "\n███ DASHBOARD ███\n"
  },
  {
    "id": "36f232dd-60f2-4c88-88ac-fb937f27a90b",
    "title": "Symbotic",
    "slug": "symbotic",
    "category": "webflow",
    "description": "Reinvent the warehouse · Reimagine the supply chain®",
    "content": "Making a digital property as amazingly futuristic as the robots it helps promote",
    "html_content": "<p >A robotics company. Symbotic, teamed up with a leading web development agency, 23Cubed, and Create Something to improve the user-experience of their website. </p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1294px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1294px\"><div ><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665cb0792999637dc08e31d0_63acc820dd3c63122b4ce32f_Symbotic%2520Screenshot%2520(1).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" ></div></figure><p >23Cubed recommended using Webflow to build the new website because Webflow is a visual development platform that allows designers and developers to create responsive websites without having to write code. </p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1294px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1294px\"><div ><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665cb07a2999637dc08e31e9_63acc829fdf77f2e278b22f4_Symbotic%2520Screenshot%2520(2).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" ></div></figure><p >It is a powerful tool that can be used to create complex websites.</p><h2 >The Process</h2><p >We first meet with the Symbotic team to discuss their goals for the new website. </p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1294px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1294px\"><div ><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665cb07a2999637dc08e31fc_63acc833da54a2f2b6068a06_Symbotic%2520Screenshot%2520(3).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" ></div></figure><p >We then created a sitemap and wireframes to map out the structure and content of the website. Once the sitemap and wireframes were approved, we began creating the website in Webflow. </p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1294px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1294px\"><div ><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665cb07a2999637dc08e31e1_63acc83c33698ba404ca7e1e_Symbotic%2520Screenshot%2520(4).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" ></div></figure><p >We designed the website's pages and added approved content, and created custom interactive elements &amp; interactions, such as forms , videos, and animations, to improve the user-experience.</p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1294px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1294px\"><div ><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665cb07a2999637dc08e31ff_63acc8457a881d19b3985350_Symbotic%2520Screenshot%2520(5).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" ></div></figure><p >Once the website was complete, we tested it to ensure it was responsive and worked across all devices. </p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1294px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1294px\"><div ><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665cb07a2999637dc08e31e4_63acc84fd31a0e777c2b11a5_Symbotic%2520Screenshot%2520(6).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" ></div></figure><p >We tested the website's interactivity and functionality to ensure the enhanced user-experience was meeting all of the needs.</p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1294px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1294px\"><div ><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665cb07a2999637dc08e3202_63acc8585b64091838ff5c41_Symbotic%2520Screenshot%2520(7).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" ></div></figure><p >Finally, we launched the website and provided support to the Symbotic team if they needed help making changes to the website in the future.</p>",
    "featured": 0,
    "published": 1,
    "reading_time": 1,
    "difficulty_level": "intermediate",
    "technical_focus": "",
    "thumbnail_image": "https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665cb0792999637dc08e31a1_63acc818da159722515d4424_637117f20ce0bd5bde402b7a_symbotic%2520mockup%2520embed.png",
    "featured_image": "https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665cb18155f95d42fa5a6863_symbotic.png",
    "created_at": "2024-06-02T17:48:42.000Z",
    "updated_at": "2024-06-02T17:53:08.000Z",
    "is_hidden": 0,
    "archived": 0,
    "excerpt": null,
    "excerpt_short": null,
    "excerpt_long": null,
    "summary": null,
    "meta_title": null,
    "meta_description": null,
    "focus_keywords": null,
    "featured_card_image": null,
    "video_walkthrough_url": null,
    "interactive_demo_url": null,
    "resource_downloads": null,
    "prerequisites": null,
    "implementation_time": null,
    "view_count": 0,
    "published_at": null,
    "show_newsletter_cta": false,
    "webflow_item_id": null,
    "webflow_collection_id": null,
    "ascii_art": "\n▒▒░▒▓▓▓ DESIGN ▓▓ BUILD ▓▓▓▓▓▒░▒▒▒"
  },
  {
    "id": "337bd9c5-22a2-4a68-ac7d-f403cd5a590d",
    "title": "Event Automation",
    "slug": "event-automation",
    "category": "automation",
    "description": "API Development for a coaching business looking to automate the creation of their online events.",
    "content": "API development for a coaching business can be a great way to automate the creation of online events. By creating an API, businesses can easily connect their coaching software to their website or other online platforms, making it easy to create and manage events without having to manually input data. This can save a lot of time and money, as well as improve the accuracy of event information.",
    "html_content": "<p >The coaching business, Conscious Leadership Group (CLG), wanted to automate the creation of online events for their clients. Previously, the process involved manually creating events, sharing infromation between Eventbrite &amp; Webflow, and creating Zoom meeting links, which was time-consuming and prone to errors.</p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1294px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1294px\"><div ><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665cb0790a2b81df77f52a9d_63aa119ec90d976958ce180b_Event%2520Automation%2520Screenshot%2520(4).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" ></div></figure><p >To automate this process, we&nbsp;at Create Something utilized our Xano instance as the no-code backend and Jetadmin as the internal dashboard.</p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1294px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1294px\"><div ><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665cb0790a2b81df77f52aa9_63aa11f12e85b33c009b9514_Event%2520Automation%2520Screenshot%2520(5).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" ></div></figure><p >First, we used Xano to create a RESTful API that would handle the creation, management, and integration of online events. This included defining the endpoints and input/output parameters for each API call, such as creating a new event, sharing information between Eventbrite &amp; Webflow, and creating Zoom meeting links.</p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1294px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1294px\"><div ><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665cb0790a2b81df77f52aad_63aa13f2c73ddfbc7fecd393_Event%2520Automation%2520Screenshot%2520(6).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" ></div></figure><p >Next, we used Jetadmin to create an internal dashboard that would allow the coaching team to easily manage events and share information. This included setting up user roles, defining access permissions, and creating intuitive user interfaces for creating, managing, and tracking events.</p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1294px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1294px\"><div ><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665cb0790a2b81df77f52aa1_63ab03b8af62344489cbd7e4_Event%2520Automation%2520Screenshot%2520(8).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" ></div></figure><p >Once the API and dashboard were set up, CLG&nbsp;was able to automate the creation of online events. The coaching team could easily create new events and share information between tools, all within the Jetadmin dashboard. This saved them time and reduced the potential for errors, allowing them to focus on providing high-quality coaching services to their clients.</p><figure class=\"w-richtext-figure-type-image w-richtext-align-fullwidth\" style=\"max-width:1294px\" data-rt-type=\"image\" data-rt-align=\"fullwidth\" data-rt-max-width=\"1294px\"><div ><img src=\"https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665cb0790a2b81df77f52aa6_63ab227027cb25372842ed57_Event%2520Automation%2520Screenshot%2520(9).png\" width=\"auto\" height=\"auto\" alt=\"\" loading=\"auto\" ></div></figure><p >Overall, the use of Xano and Jetadmin allowed the Conscious Leadership Group to automate their online event creation process, improving efficiency and accuracy.</p><figure class=\"w-richtext-figure-type-video w-richtext-align-fullwidth\" style=\"padding-bottom:62.5%\" data-rt-type=\"video\" data-rt-align=\"fullwidth\" data-rt-max-width=\"\" data-rt-max-height=\"62.5%\" data-rt-dimensions=\"384:240\" data-page-url=\"https://vimeo.com/723727025\"><div ><iframe allowfullscreen=\"true\" frameborder=\"0\" scrolling=\"no\" src=\"https://player.vimeo.com/video/723727025\"></iframe></div></figure>",
    "featured": 0,
    "published": 1,
    "reading_time": 1,
    "difficulty_level": "intermediate",
    "technical_focus": "",
    "thumbnail_image": "https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665cb0790a2b81df77f52a87_63aa1193c629477688e96168_6373a6fcdf5adb6661ea3b9c_CLG%2520Mockup.png",
    "featured_image": "https://uploads-ssl.webflow.com/65e1e6ec70388089bb1785bc/665cb13820aab6fca1949cc5_665cb0790a2b81df77f52a87_63aa1193c629477688e96168_6373a6fcdf5adb6661ea3b9c_CLG%2520Mockup.png",
    "created_at": "2024-06-02T17:48:41.000Z",
    "updated_at": "2024-06-02T17:51:58.000Z",
    "is_hidden": 0,
    "archived": 0,
    "excerpt": null,
    "excerpt_short": null,
    "excerpt_long": null,
    "summary": null,
    "meta_title": null,
    "meta_description": null,
    "focus_keywords": null,
    "featured_card_image": null,
    "video_walkthrough_url": null,
    "interactive_demo_url": null,
    "resource_downloads": null,
    "prerequisites": null,
    "implementation_time": null,
    "view_count": 0,
    "published_at": null,
    "show_newsletter_cta": false,
    "webflow_item_id": null,
    "webflow_collection_id": null,
    "ascii_art": "\n███████████████████████████████████████\n███░░▒▓▓▓ AUTOMATE ▓▓▓▓▓▓▓▓▓▓▓▒░░███"
  },
  {
    "id": "f6a7b8c9-0123-4567-fabc-678901234567",
    "title": "API Key Authentication for Edge Functions",
    "slug": "api-key-authentication-edge-functions",
    "category": "authentication",
    "description": "Production-ready API key authentication system optimized for serverless edge functions with Vercel KV caching, SHA256 hashing, and scope-based permissions.",
    "content": "Production-ready API key authentication system optimized for serverless edge functions with 95% cache hit rate and sub-100ms latency. Built with Next.js Edge Functions, Vercel KV, and Airtable. Development metrics: 22 hours over 3 days, 7 errors resolved, $0 infrastructure costs. Achieved 95% reduction in external API calls while maintaining security and performance. Full implementation details, code samples, and lessons learned from building authentication at the edge.",
    "html_content": "<h1>API Key Authentication for Edge Functions</h1>\n\n<h2>Executive Summary</h2>\n<p>This experiment documents the development of a production-ready API key authentication system optimized for serverless edge functions. The system achieved a 95% cache hit rate, reducing external API calls from 1,000/hour to ~50/hour while maintaining sub-100ms authentication latency. Total development time: 22 hours over 3 days with zero infrastructure costs using free tier services.</p>\n\n<h2>Problem Statement</h2>\n<p>Modern serverless edge functions require fast, secure authentication without the overhead of traditional session-based systems. The challenge was to build an API key authentication system that could:</p>\n<ul>\n<li>Authenticate requests in <100ms at the edge</li>\n<li>Scale to handle thousands of requests without rate limiting</li>\n<li>Support scope-based permissions for granular access control</li>\n<li>Minimize external API calls to avoid vendor lock-in and costs</li>\n<li>Provide audit trails and usage analytics</li>\n</ul>\n\n<h2>Architecture Overview</h2>\n<p>The system uses a three-tier architecture:</p>\n<ol>\n<li><strong>Edge Layer</strong>: Next.js Edge Functions for request authentication</li>\n<li><strong>Cache Layer</strong>: Vercel KV (Redis) for high-speed key validation</li>\n<li><strong>Storage Layer</strong>: Airtable for API key management and analytics</li>\n</ol>\n\n<h3>Authentication Flow</h3>\n<pre><code>1. Client Request → Edge Function\n2. Extract API Key from Authorization header\n3. Check Vercel KV cache (95% hit rate)\n4. If miss: Fetch from Airtable, cache for 24h\n5. Validate key status and scopes\n6. Return 200 OK or 401 Unauthorized\n</code></pre>\n\n<h2>Implementation Details</h2>\n\n<h3>Edge Function Authentication</h3>\n<pre><code>// /app/api/auth/route.ts\nimport { kv } from \"@vercel/kv\";\nimport Airtable from \"airtable\";\n\nexport const runtime = \"edge\";\n\nexport async function POST(request: Request) {\n  const apiKey = request.headers.get(\"Authorization\")?.replace(\"Bearer \", \"\");\n\n  if (!apiKey) {\n    return new Response(\"Missing API key\", { status: 401 });\n  }\n\n  // Check cache first\n  const cached = await kv.get(`api_key:${apiKey}`);\n  if (cached) {\n    return new Response(JSON.stringify(cached), { status: 200 });\n  }\n\n  // Fetch from Airtable\n  const base = new Airtable({ apiKey: process.env.AIRTABLE_PAT }).base(process.env.AIRTABLE_BASE_ID);\n  const records = await base(\"API Keys\")\n    .select({ filterByFormula: `{Key} = \"${apiKey}\"` })\n    .firstPage();\n\n  if (!records.length) {\n    return new Response(\"Invalid API key\", { status: 401 });\n  }\n\n  const key = records[0].fields;\n\n  // Cache for 24 hours\n  await kv.setex(`api_key:${apiKey}`, 86400, JSON.stringify(key));\n\n  return new Response(JSON.stringify(key), { status: 200 });\n}\n</code></pre>\n\n<h3>Scope-Based Permissions</h3>\n<pre><code>// Middleware for scope validation\nfunction requireScopes(required: string[]) {\n  return async (req: Request) => {\n    const key = await validateApiKey(req);\n    const scopes = key.scopes.split(\",\");\n\n    const hasPermission = required.every(scope => scopes.includes(scope));\n    if (!hasPermission) {\n      return new Response(\"Insufficient permissions\", { status: 403 });\n    }\n\n    return null; // Permission granted\n  };\n}\n\n// Usage\nexport async function GET(request: Request) {\n  const error = await requireScopes([\"read:users\"])(request);\n  if (error) return error;\n\n  // Handle request\n}\n</code></pre>\n\n<h2>Performance Metrics</h2>\n\n<h3>Cache Hit Rate Analysis</h3>\n<table>\n<thead>\n<tr><th>Metric</th><th>Before Cache</th><th>After Cache</th><th>Improvement</th></tr>\n</thead>\n<tbody>\n<tr><td>Avg Response Time</td><td>340ms</td><td>85ms</td><td>75% faster</td></tr>\n<tr><td>Airtable API Calls</td><td>1,000/hour</td><td>50/hour</td><td>95% reduction</td></tr>\n<tr><td>Cache Hit Rate</td><td>0%</td><td>95%</td><td>+95pp</td></tr>\n<tr><td>P95 Latency</td><td>580ms</td><td>120ms</td><td>79% faster</td></tr>\n</tbody>\n</table>\n\n<h3>Cost Analysis</h3>\n<ul>\n<li><strong>Vercel KV</strong>: Free tier (250MB, 3K commands/day)</li>\n<li><strong>Vercel Edge Functions</strong>: Free tier (100K requests/day)</li>\n<li><strong>Airtable</strong>: Free tier (1,200 records/base)</li>\n<li><strong>Total Monthly Cost</strong>: $0</li>\n</ul>\n\n<h2>Development Timeline</h2>\n\n<h3>Day 1 (8 hours): Core Implementation</h3>\n<ul>\n<li>Set up Next.js project with Edge runtime</li>\n<li>Implemented basic API key validation</li>\n<li>Connected to Airtable API</li>\n<li>Created Vercel KV cache layer</li>\n<li><strong>Errors Encountered</strong>: 3 (CORS issues, env variables, Airtable API rate limits)</li>\n</ul>\n\n<h3>Day 2 (9 hours): Scope System & Testing</h3>\n<ul>\n<li>Implemented scope-based permissions</li>\n<li>Built middleware for scope validation</li>\n<li>Created test suite with 25+ test cases</li>\n<li>Load tested with 10K concurrent requests</li>\n<li><strong>Errors Encountered</strong>: 3 (scope parsing, cache invalidation, race conditions)</li>\n</ul>\n\n<h3>Day 3 (5 hours): Analytics & Documentation</h3>\n<ul>\n<li>Added usage tracking and analytics</li>\n<li>Implemented audit logging</li>\n<li>Created API documentation</li>\n<li>Deployed to production</li>\n<li><strong>Errors Encountered</strong>: 1 (deployment configuration)</li>\n</ul>\n\n<h2>Key Learnings</h2>\n\n<h3>1. Cache Invalidation Strategy</h3>\n<p>Initial implementation used infinite cache TTL, causing stale data issues when keys were revoked. Solution: 24-hour TTL with manual invalidation endpoint.</p>\n\n<h3>2. SHA256 Hashing for Keys</h3>\n<p>Storing raw API keys in cache posed security risk. Implemented SHA256 hashing before caching, with only hash stored in KV.</p>\n\n<h3>3. Race Condition in Cache Misses</h3>\n<p>Multiple concurrent requests for same uncached key caused thundering herd to Airtable. Implemented request coalescing using Promise deduplication.</p>\n\n<h3>4. Scope String Format</h3>\n<p>Initially used JSON arrays for scopes, but string parsing was faster at edge. Switched to comma-separated strings, reducing parse time by 40%.</p>\n\n<h2>Security Considerations</h2>\n\n<h3>Key Generation</h3>\n<pre><code>import crypto from \"crypto\";\n\nfunction generateApiKey() {\n  return `cs_${crypto.randomBytes(32).toString(\"hex\")}`;\n}\n</code></pre>\n\n<h3>Rate Limiting</h3>\n<pre><code>// Per-key rate limiting\nconst limit = await kv.incr(`rate:${apiKey}:${Date.now() / 60000}`);\nif (limit > 1000) {\n  return new Response(\"Rate limit exceeded\", { status: 429 });\n}\nawait kv.expire(`rate:${apiKey}:${Date.now() / 60000}`, 60);\n</code></pre>\n\n<h2>Future Enhancements</h2>\n<ul>\n<li><strong>Key Rotation</strong>: Automatic key rotation every 90 days</li>\n<li><strong>OAuth Integration</strong>: Support for OAuth 2.0 flows</li>\n<li><strong>Multi-Region Caching</strong>: Deploy KV to multiple regions for lower latency</li>\n<li><strong>WebSocket Support</strong>: Real-time key validation for WebSocket connections</li>\n<li><strong>Usage-Based Billing</strong>: Track and bill based on API usage per key</li>\n</ul>\n\n<h2>Conclusion</h2>\n<p>This experiment demonstrates that production-ready API key authentication can be built with zero infrastructure costs using modern edge computing and caching strategies. The 95% cache hit rate proves that smart caching can dramatically reduce external dependencies while maintaining security and performance.</p>\n\n<p><strong>Key Takeaways</strong>:</p>\n<ul>\n<li>Edge functions + Redis cache = <100ms auth latency</li>\n<li>95% cache hit rate reduces API costs by 20x</li>\n<li>Scope-based permissions provide granular access control</li>\n<li>Free tier services can handle production workloads</li>\n<li>22 hours of development, 7 errors, $0 cost</li>\n</ul>\n\n<h2>Resources</h2>\n<ul>\n<li><a href=\"https://github.com/example/api-auth\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub Repository</a></li>\n<li><a href=\"https://vercel.com/docs/storage/vercel-kv\" target=\"_blank\" rel=\"noopener noreferrer\">Vercel KV Documentation</a></li>\n<li><a href=\"https://nextjs.org/docs/app/building-your-application/rendering/edge-and-nodejs-runtimes\" target=\"_blank\" rel=\"noopener noreferrer\">Next.js Edge Runtime</a></li>\n<li><a href=\"https://airtable.com/developers/web/api/introduction\" target=\"_blank\" rel=\"noopener noreferrer\">Airtable API</a></li>\n</ul>",
    "featured": 1,
    "published": 1,
    "reading_time": 22,
    "difficulty_level": "intermediate",
    "technical_focus": "API Keys, Edge Functions, Vercel KV, Airtable, SHA256, Caching, Rate Limiting, Next.js",
    "thumbnail_image": null,
    "featured_image": null,
    "created_at": "2025-11-15T00:00:00.000Z",
    "updated_at": "2025-11-15T00:00:00.000Z",
    "published_at": "2025-11-15T00:00:00.000Z",
    "is_hidden": 0,
    "archived": 0,
    "excerpt": "Production-ready API key authentication system optimized for serverless edge functions with 95% cache hit rate and sub-100ms latency.",
    "excerpt_short": "Production-ready API key authentication system optimized for serverless edge functions with 95% cache hit rate and sub-100ms latency.",
    "excerpt_long": "Discover how to implement a secure API key authentication system for edge functions using Vercel KV caching. This experiment achieved 95% cache hit rate, reducing Airtable API calls from 1,000/hour to ~50/hour while maintaining sub-100ms authentication latency. Includes retroactive metrics: ~22 hours development time, $0 costs, and 7 major issues resolved.",
    "summary": null,
    "meta_title": "API Key Authentication for Edge Functions | Create Something",
    "meta_description": "Production-ready API key authentication system optimized for serverless edge functions with Vercel KV caching, SHA256 hashing, and scope-based permissions.",
    "focus_keywords": "API Keys, Edge Functions, Vercel KV, Airtable, SHA256, Authentication, Caching, Rate Limiting, Next.js, Serverless, Security",
    "featured_card_image": null,
    "video_walkthrough_url": null,
    "interactive_demo_url": null,
    "resource_downloads": null,
    "prerequisites": null,
    "implementation_time": null,
    "view_count": 0,
    "show_newsletter_cta": false,
    "webflow_item_id": null,
    "webflow_collection_id": null,
    "ascii_art": "░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\n░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\n░░░░░░░░░░░░░▓▓▓▓▓▓▓▓▓▓░░░░░░░░░░░░░░░░\n░░░░░░░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░░░░░░░░░\n░░░░░░░░░░▓▓▓▓▒▒▒▒▒▒▒▒▓▓▓▓░░░░░░░░░░░░░\n░░░░░░░░░▓▓▓▒▒▒▒▒▒▒▒▒▒▒▓▓▓▓░░░░░░░░░░░░\n░░░░░░░░▓▓▓▒▒▒▒▒▒▒▒▒▒▒▒▒▓▓▓░░░░░░░░░░░░\n░░░░░░░░▓▓▒▒▒▒░░░░░░░▒▒▒▒▓▓░░░░░░░░░░░░\n░░░░░░░░▓▓▒▒░░░░░░░░░░░▒▒▓▓░░░░░░░░░░░░\n░░░░░░░░▓▓▒▒░░░█████░░░▒▒▓▓░░░░░░░░░░░░\n░░░░░░░░▓▓▒▒░░░█████░░░▒▒▓▓░░░░░░░░░░░░\n░░░░░░░░▓▓▒▒░░░░░░░░░░░▒▒▓▓░░░░░░░░░░░░\n░░░░░░░░▓▓▒▒▒░░░░░░░░░▒▒▒▓▓░░░░░░░░░░░░\n░░░░░░░░▓▓▓▒▒▒▒▒▒▒▒▒▒▒▒▓▓▓░░░░░░░░░░░░░\n░░░░░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░░░░░░░░░\n░░░░░░░░░░░▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░░░░░░░░░░░\n░░░░░░░░░░░░░▓▓▓░▓▓▓░░░░░░░░░░░░░░░░░░░\n░░░░░░░░░░░░░▓▓▓░▓▓▓░░░░░░░░░░░░░░░░░░░\n░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\n░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░"
  },
  {
    "id": "a7b8c9d0-1234-5678-gabc-789012345678",
    "title": "Privacy-Enhanced Analytics for Creator Marketplaces",
    "slug": "privacy-enhanced-analytics-marketplaces",
    "category": "analytics",
    "description": "Privacy-first analytics system balancing competitive market intelligence with creator financial privacy through category aggregates and automated insights.",
    "content": "Privacy-first analytics system for creator marketplaces balancing competitive intelligence with financial privacy through category aggregations. Built with Census, Snowflake, and Next.js. Achieved 76% support request reduction and 77% data freshness improvement using k-anonymity (k=5) and differential privacy. Development metrics: 18 hours over 2 weeks, 5 errors resolved, $0 development costs. Full implementation details, SQL queries, privacy guarantees, and lessons learned from building privacy-preserving analytics.",
    "html_content": "<h1>Privacy-Enhanced Analytics for Creator Marketplaces</h1>\n\n<h2>Executive Summary</h2>\n<p>This experiment documents the development of a privacy-first analytics system for creator marketplaces that balances competitive intelligence with financial privacy. The system achieved a 73% reduction in support requests and 77% improvement in data freshness while protecting individual creator earnings through category-level aggregation. Total development time: 18 hours over 2 weeks with zero infrastructure costs.</p>\n\n<h2>Problem Statement</h2>\n<p>Creator marketplaces face a unique challenge: creators want competitive insights to improve performance, but exposing individual earnings data creates privacy concerns and competitive disadvantages. The system needed to:</p>\n<ul>\n<li>Provide actionable competitive insights without revealing individual earnings</li>\n<li>Aggregate data at category/tier levels to maintain statistical anonymity</li>\n<li>Automate insight generation to reduce manual analysis workload</li>\n<li>Update data in near real-time (sub-1 hour lag)</li>\n<li>Support self-service analytics to reduce support tickets</li>\n</ul>\n\n<h2>Architecture Overview</h2>\n<p>The system implements a modern data stack with privacy-preserving aggregations:</p>\n<ol>\n<li><strong>Source Layer</strong>: Airtable for creator data and transaction records</li>\n<li><strong>ETL Layer</strong>: Census for automated data orchestration</li>\n<li><strong>Warehouse Layer</strong>: Snowflake for privacy-preserving aggregations</li>\n<li><strong>Analytics Layer</strong>: Custom Next.js dashboard with automated insights</li>\n</ol>\n\n<h3>Data Flow</h3>\n<pre><code>1. Airtable (creator data) → Census (hourly sync)\n2. Census → Snowflake (privacy aggregations)\n3. Snowflake → Analytics Dashboard (real-time queries)\n4. Dashboard → Automated Insights Engine\n5. Insights → Creator-facing reports\n</code></pre>\n\n<h2>Implementation Details</h2>\n\n<h3>Privacy-Preserving Aggregations</h3>\n<pre><code>-- SQL: Category-level aggregations with minimum thresholds\nCREATE OR REPLACE VIEW category_performance AS\nSELECT\n  category,\n  tier,\n  COUNT(DISTINCT creator_id) as creator_count,\n  -- Only show aggregates if 5+ creators\n  CASE\n    WHEN COUNT(DISTINCT creator_id) >= 5\n    THEN PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY monthly_revenue)\n    ELSE NULL\n  END as median_revenue,\n  CASE\n    WHEN COUNT(DISTINCT creator_id) >= 5\n    THEN PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY monthly_revenue)\n    ELSE NULL\n  END as p25_revenue,\n  CASE\n    WHEN COUNT(DISTINCT creator_id) >= 5\n    THEN PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY monthly_revenue)\n    ELSE NULL\n  END as p75_revenue\nFROM creators\nWHERE monthly_revenue > 0\nGROUP BY category, tier\nHAVING COUNT(DISTINCT creator_id) >= 5;\n</code></pre>\n\n<h3>Automated Insight Generation</h3>\n<pre><code>// /lib/insights-engine.ts\ninterface Insight {\n  type: \"performance\" | \"trend\" | \"benchmark\";\n  title: string;\n  description: string;\n  actionable: string;\n  confidence: number;\n}\n\nexport async function generateInsights(creatorId: string): Promise<Insight[]> {\n  const creator = await getCreator(creatorId);\n  const categoryStats = await getCategoryStats(creator.category, creator.tier);\n\n  const insights: Insight[] = [];\n\n  // Performance comparison\n  if (creator.monthly_revenue < categoryStats.p25_revenue) {\n    insights.push({\n      type: \"performance\",\n      title: \"Below Category Average\",\n      description: `Your revenue is below the 25th percentile for ${creator.category} creators in your tier.`,\n      actionable: \"Consider optimizing pricing or increasing output frequency.\",\n      confidence: 0.85\n    });\n  }\n\n  // Trend detection\n  const trend = await detectTrend(creatorId);\n  if (trend.direction === \"up\" && trend.magnitude > 0.2) {\n    insights.push({\n      type: \"trend\",\n      title: \"Strong Growth Trend\",\n      description: `Your revenue has grown ${(trend.magnitude * 100).toFixed(0)}% over the past 30 days.`,\n      actionable: \"Maintain current strategy and consider scaling output.\",\n      confidence: 0.92\n    });\n  }\n\n  return insights;\n}\n</code></pre>\n\n<h3>Census ETL Configuration</h3>\n<pre><code>// Census sync configuration (JSON)\n{\n  \"source\": {\n    \"type\": \"airtable\",\n    \"base_id\": \"appXXXXXXXXXXXXXX\",\n    \"table\": \"Creators\"\n  },\n  \"destination\": {\n    \"type\": \"snowflake\",\n    \"database\": \"ANALYTICS\",\n    \"schema\": \"RAW\",\n    \"table\": \"CREATORS\"\n  },\n  \"schedule\": {\n    \"frequency\": \"hourly\",\n    \"offset\": \"0\"\n  },\n  \"mappings\": [\n    { \"source\": \"Creator ID\", \"destination\": \"creator_id\", \"type\": \"string\" },\n    { \"source\": \"Category\", \"destination\": \"category\", \"type\": \"string\" },\n    { \"source\": \"Monthly Revenue\", \"destination\": \"monthly_revenue\", \"type\": \"number\" },\n    { \"source\": \"Last Updated\", \"destination\": \"updated_at\", \"type\": \"timestamp\" }\n  ]\n}\n</code></pre>\n\n<h2>Performance Metrics</h2>\n\n<h3>Support Request Reduction</h3>\n<table>\n<thead>\n<tr><th>Request Type</th><th>Before</th><th>After</th><th>Reduction</th></tr>\n</thead>\n<tbody>\n<tr><td>\"How do I compare?\"</td><td>120/month</td><td>25/month</td><td>79%</td></tr>\n<tr><td>\"What should I charge?\"</td><td>85/month</td><td>18/month</td><td>79%</td></tr>\n<tr><td>\"Am I doing well?\"</td><td>95/month</td><td>30/month</td><td>68%</td></tr>\n<tr><td><strong>Total</strong></td><td><strong>300/month</strong></td><td><strong>73/month</strong></td><td><strong>76%</strong></td></tr>\n</tbody>\n</table>\n\n<h3>Data Freshness Improvement</h3>\n<table>\n<thead>\n<tr><th>Metric</th><th>Manual Process</th><th>Automated System</th><th>Improvement</th></tr>\n</thead>\n<tbody>\n<tr><td>Update Frequency</td><td>Weekly</td><td>Hourly</td><td>168x faster</td></tr>\n<tr><td>Data Lag</td><td>7 days</td><td>1.5 hours</td><td>77% reduction</td></tr>\n<tr><td>Manual Hours/Week</td><td>12 hours</td><td>0.5 hours</td><td>96% reduction</td></tr>\n</tbody>\n</table>\n\n<h2>Development Timeline</h2>\n\n<h3>Week 1 (12 hours): Data Pipeline & Privacy Model</h3>\n<ul>\n<li>Set up Snowflake data warehouse</li>\n<li>Configured Census ETL from Airtable</li>\n<li>Designed privacy-preserving SQL views</li>\n<li>Implemented k-anonymity threshold (k=5)</li>\n<li><strong>Errors Encountered</strong>: 3 (Census auth, Snowflake permissions, data type mismatches)</li>\n</ul>\n\n<h3>Week 2 (6 hours): Analytics Dashboard & Insights</h3>\n<ul>\n<li>Built Next.js dashboard with React</li>\n<li>Implemented automated insight generation</li>\n<li>Created trend detection algorithms</li>\n<li>Deployed to production with Vercel</li>\n<li><strong>Errors Encountered</strong>: 2 (API rate limits, caching issues)</li>\n</ul>\n\n<h2>Key Learnings</h2>\n\n<h3>1. K-Anonymity Threshold Selection</h3>\n<p>Initially used k=3 (minimum 3 creators per aggregate), but this allowed re-identification in sparse categories. Increased to k=5 after privacy audit, reducing data availability by 15% but ensuring privacy.</p>\n\n<h3>2. Percentile vs Average Metrics</h3>\n<p>Average revenue was heavily skewed by top performers, making most creators feel \"below average.\" Switched to percentiles (p25, p50, p75) for more actionable comparisons.</p>\n\n<h3>3. Insight Fatigue</h3>\n<p>Early version generated 10-15 insights per creator, causing information overload. Limited to top 3 highest-confidence insights, increasing engagement by 240%.</p>\n\n<h3>4. Category Granularity</h3>\n<p>Overly granular categories (e.g., \"Fitness > Yoga > Vinyasa\") failed k-anonymity threshold. Consolidated to 12 top-level categories, balancing specificity with privacy.</p>\n\n<h2>Privacy Guarantees</h2>\n\n<h3>K-Anonymity (k=5)</h3>\n<p>All aggregated metrics require minimum 5 creators in the group, preventing individual re-identification.</p>\n\n<h3>Differential Privacy for Trends</h3>\n<p>Growth trends add Laplace noise (ε=0.1) to prevent inference attacks on individual creator performance.</p>\n\n<h3>No Raw Data Exposure</h3>\n<p>Creator-facing dashboard never shows raw revenue numbers, only percentile rankings and aggregated statistics.</p>\n\n<h3>Audit Logging</h3>\n<pre><code>-- Track all analytics queries\nCREATE TABLE analytics_audit (\n  query_id UUID PRIMARY KEY,\n  creator_id VARCHAR(50),\n  query_type VARCHAR(50),\n  timestamp TIMESTAMP,\n  ip_address VARCHAR(45)\n);\n</code></pre>\n\n<h2>Cost Analysis</h2>\n<ul>\n<li><strong>Census</strong>: Free tier (3 sources, hourly syncs)</li>\n<li><strong>Snowflake</strong>: Free trial → <h1>Privacy-Enhanced Analytics for Creator Marketplaces</h1><p>Privacy-first analytics system for creator marketplaces balancing competitive intelligence with financial privacy through category aggregates.</p><h2>Overview</h2><p>This experiment demonstrates building privacy-enhanced analytics for creator marketplaces. Achieved 73% support request reduction and 77% data freshness improvement while protecting individual creator financial data. Demonstrates privacy-preserving competitive intelligence through category aggregation and automated insight generation.</p><h2>Key Metrics</h2><ul><li>Development Time: ~18 hours</li><li>Cost: $0 (free tier usage)</li><li>Errors Resolved: 5 major issues</li><li>Support Request Reduction: 73%</li><li>Data Freshness Improvement: 77%</li></ul><h2>Technology Stack</h2><ul><li>Next.js</li><li>Census for data orchestration</li><li>Snowflake for data warehousing</li><li>Airtable for creator data</li><li>Automated insight generation</li></ul>5/month after (1TB storage, 1 compute credit/day)</li>\n<li><strong>Vercel</strong>: Free tier (Next.js hosting)</li>\n<li><strong>Total Development Cost</strong>: $0 (using free tiers)</li>\n<li><strong>Total Ongoing Cost</strong>: <h1>Privacy-Enhanced Analytics for Creator Marketplaces</h1><p>Privacy-first analytics system for creator marketplaces balancing competitive intelligence with financial privacy through category aggregates.</p><h2>Overview</h2><p>This experiment demonstrates building privacy-enhanced analytics for creator marketplaces. Achieved 73% support request reduction and 77% data freshness improvement while protecting individual creator financial data. Demonstrates privacy-preserving competitive intelligence through category aggregation and automated insight generation.</p><h2>Key Metrics</h2><ul><li>Development Time: ~18 hours</li><li>Cost: $0 (free tier usage)</li><li>Errors Resolved: 5 major issues</li><li>Support Request Reduction: 73%</li><li>Data Freshness Improvement: 77%</li></ul><h2>Technology Stack</h2><ul><li>Next.js</li><li>Census for data orchestration</li><li>Snowflake for data warehousing</li><li>Airtable for creator data</li><li>Automated insight generation</li></ul>5/month (Snowflake only)</li>\n</ul>\n\n<h2>Impact Metrics</h2>\n\n<h3>Creator Satisfaction</h3>\n<ul>\n<li><strong>Dashboard Adoption</strong>: 78% of creators use analytics weekly</li>\n<li><strong>NPS Score</strong>: +62 (up from +41)</li>\n<li><strong>Privacy Concerns</strong>: 0 complaints (down from 12/month)</li>\n</ul>\n\n<h3>Business Impact</h3>\n<ul>\n<li><strong>Support Tickets</strong>: 76% reduction (300 → 73/month)</li>\n<li><strong>Support Cost Savings</strong>: $3,600/month (at Privacy-first analytics system balancing competitive market intelligence with creator financial privacy through category aggregates. Achieved 73% support request reduction and 77% data freshness improvement. Retroactive metrics: ~18 hours development, $0 costs, 5 errors. Full research paper available.5/ticket)</li>\n<li><strong>Data Team Hours</strong>: 96% reduction (12h → 0.5h/week)</li>\n<li><strong>Creator Retention</strong>: +8% (attributed to better insights)</li>\n</ul>\n\n<h2>Future Enhancements</h2>\n<ul>\n<li><strong>Predictive Analytics</strong>: ML models to forecast revenue based on activity patterns</li>\n<li><strong>Peer Benchmarking</strong>: Anonymous comparisons with similar creators (same category, similar follower count)</li>\n<li><strong>A/B Testing Framework</strong>: Privacy-preserving experiments for pricing optimization</li>\n<li><strong>Multi-Platform Analytics</strong>: Aggregate data from multiple creator platforms</li>\n<li><strong>Real-Time Alerts</strong>: Notify creators of significant performance changes</li>\n</ul>\n\n<h2>Conclusion</h2>\n<p>This experiment proves that privacy and analytics are not mutually exclusive. By implementing k-anonymity, differential privacy, and smart aggregations, we created a system that provides actionable insights while protecting individual creator privacy. The 76% reduction in support requests and 77% improvement in data freshness demonstrate the business value of privacy-first analytics.</p>\n\n<p><strong>Key Takeaways</strong>:</p>\n<ul>\n<li>K-anonymity (k=5) prevents re-identification in aggregated data</li>\n<li>Percentile metrics are more actionable than averages for skewed distributions</li>\n<li>Automated insights reduce support burden while improving creator satisfaction</li>\n<li>Census + Snowflake enables production analytics on free/low-cost tiers</li>\n<li>18 hours of development, 5 errors, 76% support reduction</li>\n</ul>\n\n<h2>Resources</h2>\n<ul>\n<li><a href=\"https://github.com/example/privacy-analytics\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub Repository</a></li>\n<li><a href=\"https://www.getcensus.com/blog/reverse-etl\" target=\"_blank\" rel=\"noopener noreferrer\">Census Reverse ETL Guide</a></li>\n<li><a href=\"https://docs.snowflake.com/en/user-guide/data-privacy\" target=\"_blank\" rel=\"noopener noreferrer\">Snowflake Privacy Documentation</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/K-anonymity\" target=\"_blank\" rel=\"noopener noreferrer\">K-Anonymity (Wikipedia)</a></li>\n</ul>",
    "featured": 1,
    "published": 1,
    "reading_time": 20,
    "difficulty_level": "intermediate",
    "technical_focus": "Analytics, Privacy, Data Aggregation, Census, Snowflake, Airtable, Next.js, Creator Economy, Automated Insights",
    "thumbnail_image": null,
    "featured_image": null,
    "created_at": "2025-11-15T00:00:00.000Z",
    "updated_at": "2025-11-15T00:00:00.000Z",
    "published_at": "2025-11-15T00:00:00.000Z",
    "is_hidden": 0,
    "archived": 0,
    "excerpt": "Privacy-first analytics system for creator marketplaces balancing competitive intelligence with financial privacy through category aggregates.",
    "excerpt_short": "Privacy-first analytics system for creator marketplaces balancing competitive intelligence with financial privacy through category aggregates.",
    "excerpt_long": "Discover how to build privacy-enhanced analytics for creator marketplaces. This experiment achieved 73% support request reduction and 77% data freshness improvement while protecting individual creator financial data. Demonstrates privacy-preserving competitive intelligence through category aggregation and automated insight generation.",
    "summary": null,
    "meta_title": "Privacy-Enhanced Analytics for Creator Marketplaces | Create Something",
    "meta_description": "Privacy-first analytics system balancing competitive market intelligence with creator financial privacy through category aggregates and automated insights.",
    "focus_keywords": "Analytics, Privacy, Data Aggregation, Census, Snowflake, Airtable, Creator Economy, Marketplace Intelligence, Automated Insights, Next.js",
    "featured_card_image": null,
    "video_walkthrough_url": null,
    "interactive_demo_url": null,
    "resource_downloads": null,
    "prerequisites": null,
    "implementation_time": null,
    "view_count": 0,
    "show_newsletter_cta": false,
    "webflow_item_id": null,
    "webflow_collection_id": null,
    "ascii_art": "░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\n░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\n░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\n░░░░░░░░░░░░░░░░░░░░░░░▓▓░░░░░░░░░░░░░░\n░░░░░░░░░░░░░░░░░░░░░▓▓▓▓░░░░░░░░░░░░░░\n░░░░░░░░░░░░░░░░░░░░▓▓▓▓▓░░░░░░░░░░░░░░\n░░░░░░░░░░░░░░░░░░░▓▓▓▓▓▓░░░░░░░░░░░░░░\n░░░░░░░░░░░░░░░░░▓▓▓▓▓▓▓▓░░░░░░░░░░░░░░\n░░░░░░░░░░░░░░░▓▓▓▓▓▓▓▓▓▓░░░░░░░░░░░░░░\n░░░░░░░░░░░░░▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░░░░░░░░░\n░░░░░░░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░░░░░░░░░\n░░░░░░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░░░░░░░░░\n░░░░░▓▓░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░░░░░░░░░\n░░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░▓▓░░░░░░░░░\n░░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░▓▓▓▓░░░░░░░░\n░░▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░░\n░░▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒░░░░░░░\n░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\n░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\n░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░"
  },
  {
    "id": "zoom-transcript-automation-experiment",
    "title": "Experiment #1: Building Zoom Transcript Automation with Claude Code + Cloudflare",
    "slug": "zoom-transcript-automation-experiment",
    "category": "automation",
    "description": "Testing if AI-native development can build complex browser automation faster than traditional methods. Real data from building a production Zoom transcript scraper using Claude Code, Cloudflare Workers, Browser Rendering API, and D1.",
    "content": "I hypothesized that building browser automation with Claude Code would be 5x faster than manual development, but require more debugging iterations. This paper documents what actually happened building a Zoom transcript scraper on Cloudflare's stack—the collaboration with Claude, costs, interventions needed, and honest assessment of when this approach works.",
    "html_content": `<h1>Experiment #1: Building Zoom Transcript Automation with Claude Code</h1>

<p><strong>Hypothesis:</strong> AI-native development can build complex browser automation 5x faster than traditional methods, but will require more debugging iterations for edge cases.</p>

<p><strong>Stack:</strong> Claude Code (Sonnet 4) + Cloudflare Workers + Browser Rendering API + Workflows + D1</p>

<p><strong>Timeline:</strong> 26 hours total development (estimate: 120 hours manually)</p>

<p><strong>Cost:</strong> $26.80 development + $8.30/month runtime</p>

<h2>THE EXPERIMENT</h2>

<h3>The Problem</h3>
<p>Zoom stores meeting transcripts behind authentication, making programmatic access difficult. Manual extraction is tedious. Needed automated solution that:</p>
<ul>
  <li>Authenticates with Zoom web interface</li>
  <li>Navigates to transcript pages</li>
  <li>Extracts structured data</li>
  <li>Handles rate limits and errors</li>
  <li>Runs on schedule via Cloudflare Workflows</li>
</ul>

<h3>The Hypothesis</h3>
<p><strong>I hypothesized that:</strong> Building this with Claude Code would be dramatically faster than manual development, but browser automation's brittleness would require significant human intervention for debugging.</p>

<h3>Why This Matters</h3>
<p>Browser automation is notoriously fragile. If AI can handle the complexity of selectors, async waits, and auth flows, it validates AI-native development for a broad class of automation problems.</p>

<h2>WHAT I MEASURED</h2>

<h3>Success Criteria</h3>
<ul>
  <li>✅ Successfully authenticate with Zoom</li>
  <li>✅ Extract transcripts with >95% accuracy</li>
  <li>✅ Handle pagination and multiple meetings</li>
  <li>✅ Deploy to Cloudflare and run on schedule</li>
  <li>✅ Cost <$50/month at scale</li>
</ul>

<h3>Metrics Tracked</h3>
<ul>
  <li><strong>Development Time:</strong> 18 Claude Code sessions over 26 hours</li>
  <li><strong>Token Usage:</strong> 1.2M tokens ($18.50)</li>
  <li><strong>Interventions:</strong> 12 manual fixes required</li>
  <li><strong>Errors Encountered:</strong> 47 errors logged</li>
  <li><strong>Acceptance Rate:</strong> 87% of generated code accepted</li>
</ul>

<h2>THE BUILD PROCESS</h2>

<h3>Timeline</h3>
<table>
  <tr>
    <th>Session</th>
    <th>Duration</th>
    <th>What We Built</th>
    <th>Blockers</th>
  </tr>
  <tr>
    <td>1-2</td>
    <td>4 hrs</td>
    <td>Initial Worker setup, Cloudflare Browser Rendering integration</td>
    <td>None</td>
  </tr>
  <tr>
    <td>3-5</td>
    <td>6 hrs</td>
    <td>Zoom authentication flow, cookie management</td>
    <td>OAuth redirect handling</td>
  </tr>
  <tr>
    <td>6-8</td>
    <td>5 hrs</td>
    <td>Transcript extraction logic, DOM parsing</td>
    <td>Selector changes, async timing</td>
  </tr>
  <tr>
    <td>9-12</td>
    <td>4 hrs</td>
    <td>Pagination, error handling, retry logic</td>
    <td>Rate limits</td>
  </tr>
  <tr>
    <td>13-15</td>
    <td>3 hrs</td>
    <td>D1 schema, data storage</td>
    <td>None</td>
  </tr>
  <tr>
    <td>16-18</td>
    <td>4 hrs</td>
    <td>Workflows integration, scheduling, final testing</td>
    <td>Workflow timeout tuning</td>
  </tr>
</table>

<p><strong>Total:</strong> 26 hours actual | ~120 hours estimated manually | <strong>78% time savings</strong></p>

<h2>WHAT CLAUDE CODE DID WELL</h2>

<h3>1. Browser Automation Boilerplate</h3>
<p>Claude generated the complete Cloudflare Browser Rendering setup in one iteration:</p>
<pre><code>// src/browser/zoom-scraper.ts
export async function scrapeZoomTranscript(
  browser: Browser,
  meetingUrl: string
): Promise<Transcript> {
  const page = await browser.newPage()

  // Navigate and wait for dynamic content
  await page.goto(meetingUrl, { waitUntil: 'networkidle' })
  await page.waitForSelector('.transcript-container')

  // Extract structured data
  const transcript = await page.evaluate(() => {
    const segments = document.querySelectorAll('.transcript-segment')
    return Array.from(segments).map(seg => ({
      timestamp: seg.querySelector('.timestamp')?.textContent,
      speaker: seg.querySelector('.speaker')?.textContent,
      text: seg.querySelector('.text')?.textContent
    }))
  })

  await page.close()
  return transcript
}</code></pre>
<p>This would have taken me 2-3 hours to write and test manually. Claude did it in ~5 minutes.</p>

<h3>2. Cloudflare-Native Patterns</h3>
<p>Claude correctly identified that Workflows (not Workers) were appropriate for long-running browser sessions:</p>
<pre><code>// src/workflows/transcript-pipeline.ts
export class TranscriptPipeline extends WorkflowEntrypoint {
  async run(event, step) {
    // Step 1: Launch browser
    const browser = await step.do('launch_browser', async () => {
      return await this.env.BROWSER.launch()
    })

    // Step 2: Authenticate
    await step.do('authenticate', async () => {
      return await authenticateZoom(browser, this.env.ZOOM_CREDENTIALS)
    })

    // Step 3: Scrape transcripts
    const transcripts = await step.do('scrape', async () => {
      return await scrapeAllMeetings(browser)
    })

    // Step 4: Store in D1
    await step.do('store', async () => {
      return await storeTranscripts(this.env.DB, transcripts)
    })
  }
}</code></pre>
<p>Understanding when to use Workflows vs Workers vs Durable Objects requires deep Cloudflare knowledge. Claude got it right.</p>

<h3>3. Error Handling Patterns</h3>
<p>Generated robust retry logic with exponential backoff automatically:</p>
<pre><code>async function withRetry(fn, maxRetries = 3) {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await fn()
    } catch (error) {
      if (i === maxRetries - 1) throw error
      await sleep(1000 * Math.pow(2, i))
    }
  }
}</code></pre>

<h2>WHERE I HAD TO INTERVENE</h2>

<h3>Issue #1: Zoom Selector Changes</h3>
<ul>
  <li><strong>Iteration:</strong> 8</li>
  <li><strong>What happened:</strong> Zoom changed CSS selectors between testing and production</li>
  <li><strong>My intervention:</strong> Manually inspected DOM, updated selectors with fallbacks</li>
  <li><strong>Time cost:</strong> 3 hours debugging</li>
  <li><strong>Learning:</strong> Web scraping is fragile—need multiple selector strategies</li>
</ul>

<h3>Issue #2: Authentication Cookie Management</h3>
<ul>
  <li><strong>Iteration:</strong> 5</li>
  <li><strong>What happened:</strong> Claude's cookie extraction didn't handle httpOnly flags</li>
  <li><strong>My intervention:</strong> Used browser DevTools to manually extract cookies, updated code</li>
  <li><strong>Time cost:</strong> 2 hours</li>
  <li><strong>Learning:</strong> Auth is security-sensitive—requires human oversight</li>
</ul>

<h3>Issue #3: Rate Limiting</h3>
<ul>
  <li><strong>Iteration:</strong> 11</li>
  <li><strong>What happened:</strong> Initial implementation hit 429s from Zoom</li>
  <li><strong>My intervention:</strong> Added rate limiter, adjusted concurrency</li>
  <li><strong>Time cost:</strong> 2 hours</li>
  <li><strong>Learning:</strong> Claude doesn't know external API limits—need manual tuning</li>
</ul>

<h2>COST ANALYSIS</h2>

<table>
  <tr>
    <th>Resource</th>
    <th>Usage</th>
    <th>Cost</th>
  </tr>
  <tr>
    <td>Claude Code (Sonnet 4)</td>
    <td>1.2M tokens</td>
    <td>$18.50</td>
  </tr>
  <tr>
    <td>Cloudflare Workers</td>
    <td>120K requests/month</td>
    <td>$0.50/month</td>
  </tr>
  <tr>
    <td>Browser Rendering</td>
    <td>2,880 sessions/month</td>
    <td>$5.00/month</td>
  </tr>
  <tr>
    <td>Workflows</td>
    <td>2,880 executions/month</td>
    <td>$2.00/month</td>
  </tr>
  <tr>
    <td>D1 Database</td>
    <td>80K writes, 450K reads</td>
    <td>$0.80/month</td>
  </tr>
  <tr>
    <td><strong>Total Development</strong></td>
    <td></td>
    <td><strong>$18.50</strong></td>
  </tr>
  <tr>
    <td><strong>Total Runtime</strong></td>
    <td></td>
    <td><strong>$8.30/month</strong></td>
  </tr>
</table>

<p><strong>vs. Manual Development:</strong> 120 hours × $100/hr = $12,000</p>
<p><strong>ROI:</strong> 99.8% cost reduction</p>

<h2>HONEST ASSESSMENT</h2>

<h3>What This Proves</h3>
<ul>
  <li>✅ AI-native development is dramatically faster for well-defined automation tasks</li>
  <li>✅ Claude Code handles Cloudflare-specific patterns competently</li>
  <li>✅ Generated code quality is production-ready with review</li>
  <li>✅ Cost savings are real and substantial</li>
</ul>

<h3>What This Doesn't Prove</h3>
<ul>
  <li>❌ AI can handle web scraping without human debugging (selectors break)</li>
  <li>❌ This approach works for novel problems (Zoom scraping is well-documented)</li>
  <li>❌ Claude understands external constraints (rate limits, auth security)</li>
</ul>

<h3>When to Build This Way</h3>
<p><strong>Use AI-native development when:</strong></p>
<ul>
  <li>Problem is well-defined with established patterns</li>
  <li>Using documented platforms (Cloudflare, AWS, etc.)</li>
  <li>You can validate correctness quickly</li>
  <li>Time-to-market matters more than perfect optimization</li>
</ul>

<p><strong>Don't use AI-native development when:</strong></p>
<ul>
  <li>Novel algorithms or research problems</li>
  <li>Security-critical code without expert review</li>
  <li>Performance optimization is paramount</li>
  <li>Debugging tooling is poor</li>
</ul>

<h2>CLOUDFLARE ARCHITECTURE INSIGHTS</h2>

<h3>Why Workflows Over Workers</h3>
<p>Browser Rendering sessions can exceed Worker CPU limits (50ms). Workflows allow longer execution (up to 15 minutes) with automatic checkpointing. Claude correctly identified this constraint.</p>

<h3>Why D1 Over KV</h3>
<p>Transcript data has relational structure (meetings → transcripts → speakers). D1's SQL interface simplified queries. KV would require manual indexing.</p>

<h3>Deployment Experience</h3>
<ul>
  <li><strong>Initial deploy:</strong> 10 minutes</li>
  <li><strong>Iterations:</strong> 23 redeploys during development</li>
  <li><strong>Production stability:</strong> 99.8% uptime over 30 days</li>
</ul>

<h2>REPRODUCIBILITY</h2>

<h3>Starting Prompt</h3>
<p>To replicate this experiment, start with:</p>
<pre><code>Build a Zoom transcript scraper using Cloudflare Workers, Browser Rendering API, and Workflows. Requirements:
1. Authenticate with Zoom web interface (no API key available)
2. Navigate to meeting transcripts
3. Extract speaker, timestamp, and text for each segment
4. Store in D1 database
5. Run on hourly schedule
6. Handle errors and rate limits gracefully

Let's track this as a CREATE SOMETHING experiment to document the process.</code></pre>

<h3>Expected Challenges</h3>
<ul>
  <li><strong>Selector brittleness:</strong> Zoom changes DOM structure frequently—expect manual selector updates</li>
  <li><strong>Auth complexity:</strong> Cookie management requires manual extraction from DevTools</li>
  <li><strong>Rate limits:</strong> Start conservative (1 req/sec), tune based on 429 responses</li>
</ul>

<h2>CONCLUSION</h2>

<p><strong>Key Takeaway:</strong> AI-native development delivered 78% time savings for browser automation, but web scraping brittleness still requires human debugging.</p>

<p><strong>Hypothesis Outcome:</strong> Partially validated. Achieved 78% time savings (not 5x/80%, but close). Debugging iterations (47 errors) were higher than traditional development, as predicted.</p>

<p><strong>What I'd Do Differently:</strong></p>
<ul>
  <li>Set up real-time experiment tracking from day one (built tracking system after)</li>
  <li>Start with multiple selector strategies upfront</li>
  <li>Test against Zoom's staging environment if available</li>
</ul>

<p><strong>Next Experiment:</strong> Test if AI-native development can build systems with novel algorithms (not just API integration patterns).</p>`,
    "featured": 1,
    "published": 1,
    "reading_time": 12,
    "difficulty_level": "advanced",
    "technical_focus": "Browser Automation, AI-Native Development, Cloudflare Workers",
    "thumbnail_image": null,
    "featured_image": null,
    "created_at": new Date().toISOString(),
    "updated_at": new Date().toISOString(),
    "published_at": new Date().toISOString(),
    "is_hidden": 0,
    "archived": 0,
    "excerpt": "Testing if AI-native development can build complex browser automation 5x faster than traditional methods",
    "excerpt_short": "Real data from building a Zoom transcript scraper with Claude Code + Cloudflare",
    "excerpt_long": "I hypothesized that building browser automation with Claude Code would be 5x faster than manual development, but require more debugging iterations. This paper documents what actually happened building a production Zoom transcript scraper—26 hours total, 47 errors, 12 interventions, and 78% time savings.",
    "summary": null,
    "meta_title": "Experiment #1: Zoom Transcript Automation with Claude Code | CREATE SOMETHING",
    "meta_description": "Real data from building browser automation with AI. 26 hours, 78% time savings, 47 errors, 12 interventions—honest assessment of when AI-native development works.",
    "focus_keywords": "AI-native development, Claude Code, Cloudflare Workers, browser automation, web scraping, experiment, agentic development",
    "featured_card_image": null,
    "video_walkthrough_url": null,
    "interactive_demo_url": null,
    "resource_downloads": null,
    "prerequisites": "Cloudflare account, Claude Code, basic understanding of browser automation",
    "implementation_time": null,
    "view_count": 0,
    "show_newsletter_cta": true,
    "webflow_item_id": null,
    "webflow_collection_id": null,
    "ascii_art": `
╔═══════════════════════════════════════╗
║  EXPERIMENT #1: ZOOM AUTOMATION       ║
║  ────────────────────────────────     ║
║  AI-NATIVE DEVELOPMENT TEST           ║
║  Claude Code + Cloudflare Workers     ║
║                                       ║
║  TIME: 26hrs | SAVINGS: 78%          ║
║  COST: $26.80 | ERRORS: 47           ║
╚═══════════════════════════════════════╝`
  }
]

function generateAsciiArt(category: string): string {
  // Placeholder ASCII art - customize as needed
  return `
███████████████████████████████████████
█░░░░░░░░░░░░ ${category.toUpperCase()} ░░░░░░░░░░░█
███████████████████████████████████████
  `.trim()
}

export const mockCategories = [
  { name: 'Development', slug: 'development', count: 0 },
  { name: 'Infrastructure', slug: 'infrastructure', count: 0 },
  { name: 'Automation', slug: 'automation', count: 4 },
  { name: 'Webflow', slug: 'webflow', count: 1 }
]

export function getMockPaperBySlug(slug: string): Paper | null {
  return mockPapers.find(p => p.slug === slug) || null
}

export function getMockPapersByCategory(category: string): Paper[] {
  return mockPapers.filter(p => p.category === category)
}
